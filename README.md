# Anchoring Bias in Language Models

## Overview
This project examines the influence of anchoring bias on large language models (LLMs) and evaluates various debiasing strategies. Anchoring bias refers to the tendency of initial information, such as a stated price, to disproportionately affect subsequent decision-making processes. This repository houses the benchmark datasets, the results of model estimations, and comprehensive analysis within a Google Colab notebook.

<img src="https://github.com/user-attachments/assets/142c2fde-b71f-4083-be2c-5d70169a56a4" alt="Narrow Waist Image" width="400">

## Repository Structure
- `/images`: Contains visual aids and charts relevant to the project.
- `/input`: Includes the input data for the models, specifically the benchmark datasets.
- `/results`: Stores the outputs from the model estimations and the detailed statistical analyses.
- `README.md`: Provides an overview and instructions for navigating through the repository's contents.

## Google Colab Notebook
The analytical process and model evaluation are conducted within a Google Colab notebook, which includes scripts for prompt generation, model execution, and result analysis. The notebook is accessible [here](https://colab.research.google.com/drive/1lZJyC_pDQTUHpO6M4iEL-WaAryScadqo?authuser=3#scrollTo=onxt114EmgWO).

## Getting Started
To initiate the analysis, ensure you have access to the linked Google Colab notebook. It is advisable to commence with the README documentation, then proceed to inspect the `/input` data before engaging with the notebook. For a comprehensive analysis, you should make a copy of the notebook. This enables you to freely make changes and try to reproduce the results for verification purposes. You're also encouraged to experiment with different large language models (LLMs) or adjust the prompt engineering methods to explore how these variables might influence the results

## Analysis Results
The `/results` directory offers an in-depth look at the effects of anchoring bias and the performance of tested debiasing strategies. The Colab notebook provides extensive documentation of the findings, including statistical evidence and interpretative insights.
